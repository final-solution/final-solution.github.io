
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Yixiang Qiu's homepage">
	<link rel="stylesheet" href="./jemdoc.css" type="text/css">
	<title>Yixiang Qiu</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Yixiang Qiu &nbsp;</div>

				<h3>1-year Master degree candidate</h3>  
				<p>
					Room 1622, Information Building <br>
					Tsinghua Shenzhen International Graduate School<br>
					Shenzhen, Guangdong Province, China, 518055<br>
					<br>
Email:  <a href="mailto:qiu-yx24@mails.tsinghua.edu.cn">qiu-yx24@mails.tsinghua.edu.cn</a>; <a href="mailto:habsburgfre@gmail.com">habsburgfre@gmail.com</a> <br>
Github: <a href="https://github.com/final-solution">final-solution</a> <br>
Template: <a href="https://github.com/dongyp13/dongyp13.github.io">forked from Yinpeng Dong</a><br>
<a href="https://scholar.google.com/citations?hl=zh-CN&user=kxotrxgAAAAJ">[Google Scholar]</a><a href="https://orcid.org/0009-0000-3444-5807">[ORCID]</a><br>
				</p>
			</td>
			<td>
				<img src="./qiuyx.jpg" border="0" width="200">
			</td>
		</tr><tr>
	</tr></tbody>
</table>
<h2>Biography</h2>
<p>
	I am a first-year master's student in the ITML lab in the <a href="https://www.sigs.tsinghua.edu.cn/">SIGS</a>, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, supervised by Prof.<a href="https://binchen2021.github.io">Bin-Chen</a> and Prof.<a href="https://www.sigs.tsinghua.edu.cn/xst/list.htm">Shu-Tao Xia</a>. 
	I received my B.S. degree in Computer Science and Technology from <a href="https://www.hitsz.edu.cn/index.html">Harbin Institute of Technology, Shenzhen</a> in 2023. 
</p>
<p>
	My research interests primarily include Trustworthy AI, Generative Models, Computer Vision and Deep Learning. Currently, I work on the security for multi-modal large language models, which is going to be one of my future directions.
</p>
<h2>News</h2>

<ul>
      <li>
         [Jul. 2024] Our paper "<a href='https://arxiv.org/abs/2407.13863'>A Closer Look at GAN Priors: Exploiting Intermediate Features for Enhanced Model Inversion Attacks</a>" has been accepted as an <font color="#FF0000"><strong>Oral</strong></font> presentation in the <a href="https://eccv2024.ecva.net/">ECCV</a> 2024.
      </li>
</ul>

<h2>Publications</h2>

(* equal contribution; <sup>#</sup> corresponding author)

<h3>2024</h3>
<ul>
	<li>
         <a href='https://arxiv.org/abs/2407.13863'>A Closer Look at GAN Priors: Exploiting Intermediate Features for Enhanced Model Inversion Attacks</a>(<font color="#FF0000"><strong>Oral</strong></font>)<br>
         <strong>Yixiang Qiu*</strong>, Hao Fang*, Hongyao Yu*, Bin Chen<sup>#</sup>, Meikang Qiu, and Shu-Tao Xia<br>
         European Conference on Computer Vision<strong>(ECCV)</strong>, 2024<br>
   	</li>
</ul>

<h2>Services</h2>
<strong>Organizer for</strong>:<br>
<strong>ICCV 2023 Workshop</strong> on <a href="https://iccv23-arow.github.io">Adversarial Robustness in the Real World</a><br>
<strong>ECCV 2022 Workshop</strong> on <a href="https://eccv22-arow.github.io">Adversarial Robustness in the Real World</a><br>
<strong>AAAI 2022 Workshop</strong> on <a href="https://advml-workshop.github.io/aaai2022/">Adversarial Machine Learning and Beyond</a><br>
<strong>ICML 2021 Workshop</strong> on <a href="https://advml-workshop.github.io/icml2021/">A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning</a><br>
<strong>ICCV 2021 Workshop</strong> on <a href="https://iccv21-adv-workshop.github.io">Adversarial Robustness in the Real World</a><br>
<strong>CVPR 2021 Workshop</strong> on <a href="https://aisecure-workshop.github.io/amlcvpr2021/">Adversarial Machine Learning in Real-World Computer Vision Systems and Online Challenges (AML-CV)</a><br><br>

<strong>Reviewer for</strong>:<br>
TPAMI, IJCV, TIP, TNNLS<br>
NeurIPS, ICML, CVPR, ICLR, ICCV, ECCV, AAAI, IJCAI, etc.
<!--<strong>TPAMI</strong> 2019, 2020, 2021, 2022<br>
<strong>IJCV</strong> 2021, 2022<br>
<strong>TIP</strong> 2019, 2020, 2021<br>
<strong>TNNLS</strong> 2019, 2020<br>
<strong>NeurIPS</strong> 2016, 2019, 2020, 2021, 2022<br>
<strong>ICML</strong> 2019, 2021, 2022<br>
<strong>CVPR</strong> 2019, 2020, 2021, 2022<br>
<strong>ICLR</strong> 2020, 2021, 2022, 2023<br>
<strong>ICCV</strong> 2019, 2021<br>
<strong>ECCV</strong> 2020<br>
<strong>AAAI</strong> 2019, 2020, 2021<br>
<strong>IJCAI</strong> 2019, 2020<br>-->


<h2>Competitions</h2>

<ul>
      <li>
         Our team (Yinpeng Dong, Chang Liu, Wenzhao Xiang, Yichi Zhang, Haoxing Ye) won <font color="#FF0000">the first place</font> in the Adversarial Robustness of Deep Learning track of <a href="https://iacc.pazhoulab-huangpu.com">2022 International Algorithm Case Competition</a>.
      </li>
      <li>
         Our team (Xiao Yang, Dingcheng Yang, Shilong Liu, Zihao Xiao, Yinpeng Dong) won <font color="#FF0000">the first place</font> in the <a href="http://www.geekpwn.org/zh/index.html">GeekPwn DeepFake</a> competition (October 24th, 2020).
      </li>
      <li>
         Our team (Shuyu Cheng, Xiao Yang, Dingcheng Yang, Yinpeng Dong) won <font color="#FF0000">the first places</font> in the <a href="http://2019.geekpwn.org/en/index.html">GeekPwn CAAD CTF and Adversarial Patch</a> competitions (October 24th, 2019).
      </li>
      <li>
         Our team (Shuyu Cheng and Yinpeng Dong) won <font color="#FF0000">the second place</font> in the <a href="https://www.crowdai.org/organizers/bethgelab/challenges/nips-2018-adversarial-vision-challenge-untargeted-attack-track">Untargeted Attack track</a> of NeurIPS 2018 Adversarial Vision Challenge.
      </li>
      <li>
         Our team (Yinpeng Dong, <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/">Tianyu Pang</a>, Chao Du) won <font color="#FF0000">the second places</font> in the Targeted Adversarial Attack track and Defense Against Adversarial Attack track, as well as <font color="#FF0000">the third place</font> in the Non-targeted Adversarial Attack track of <a href="https://cn.caad.geekpwn.org">GeekPwn CAAD (Competition on Adversarial Attacks and Defenses)</a>.
         </li>
      <li>
         Our team (<a href="http://ml.cs.tsinghua.edu.cn/~tianyu/">Tianyu Pang</a>, Chao Du, Yinpeng Dong) won <font color="#FF0000">the first place</font> in <a href="http://2018.geekpwn.org/en/index.html">GeekPwn CAAD (Competition on Adversarial Attacks and Defenses) CTF</a> competition (Las Vegas) in August 10th, 2018.
         </li>
       <li>
         Our team (Yinpeng Dong, Fangzhou Liao, <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/">Tianyu Pang</a>) won <font color="#FF0000">the first places in all three sub-competitions</font> (<a href="https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack/">Non-targeted Adversarial Attacks</a>, <a href="https://www.kaggle.com/c/nips-2017-targeted-adversarial-attack/">Targeted Adversarial Attacks</a> and <a href="https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack">Defense Against Adversarial Attack</a>) of NeurIPS 2017 Adversarial Attacks and Defenses. We release our codes at <a href="https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks">[non-targeted attack]</a>, <a href="https://github.com/dongyp13/Targeted-Adversarial-Attacks">[targeted attack]</a> and <a href="https://github.com/lfz/Guided-Denoise">[defense]</a> for these three tracks. The detailed algorithms are summarized in <a href='https://arxiv.org/pdf/1710.06081.pdf'>Boosting Adversarial Attacks with Momentum</a> and <a href='https://arxiv.org/pdf/1712.02976.pdf'>Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser</a>.
       </li>
       <li>
         Our team (<a href="http://people.csail.mit.edu/yujieq/">Yujie Qian</a>, Yinpeng Dong, Ye Ma) won the <font color="#FF0000">the second place</font> in KDDCUP 2016. This <a href="https://kddcup2016.azurewebsites.net">competition</a> is about paper acceptance prediction.
</ul>


<h2>Honors &amp; Awards</h2>
<ul>
   <li> <strong>Tsinghua Outstanding Postdoctoral Researcher</strong>, 2023.07</li>
   <li> <strong>CCF Outstanding Doctoral Dissertation Award (CCF优秀博士学位论文激励计划)</strong>, 2022.12</li>
   <li> <strong>China National Postdoctoral Program for Innovative Talents (博新计划)</strong>, 2022.06</li>
   <li> <strong>Shuimu Tsinghua Scholar Program</strong>, 2022.01</li>
   <li> <strong>Beijing Outstanding Graduates</strong>, 2022.01</li>
   <li> <strong>ByteDance Scholars Program</strong>, 2020.11</li>
   <li> <strong>Tsinghua-HUAWEI Scholarship</strong>, Tsinghua University, 2020.10</li>
	<li> <strong>Baidu Fellowship</strong>, 2020.01</li>
	<li> <strong>'84' Future Innovation Scholarship</strong>, CST Department of Tsinghua University, 2019.12 <br>
		<small>This award is given to <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/">Tianyu pang</a> and me for our research on adversarial robustness.</small>
	</li>
	<li> <strong>Microsoft Research Asia (MSRA) Fellowship</strong>, 2019.11
	</li>
	<li> <strong>China National Scholarship</strong>, Tsinghua University, 2019.10</li>
	<li> <strong>VALSE Annual Outstanding Student Paper Award</strong>, 2019.04 <br>
		<small>This award is given to "Boosting Adversarial Attacks with Momentum" in CVPR 2018.</small>
	</li> 
	<li> <strong>CCF-CV Academic Emerging Award (CCF-CV 学术新锐奖)</strong>, 2018.11 <br>
		<small>Only 3 students in China were awarded for their research in computer vision during the first three years of Ph.D. career.</small>
	</li>
	<li> <strong>China National Scholarship</strong>, Tsinghua University, 2018.10</li>
	<li> <strong>Tsinghua University Future PhD Fellowship</strong>, Tsinghua University, 2017.09 <br>
		<small>This fellowship was given to only 2 students in our department.</small>
	</li>

	<!--<li> <strong>Tsinghua Outstanding Graduates</strong>, Tsinghua University, 2017.06 <br>
		<small>Only 60 students in Tsinghua were awarded for their excellent performance during the four years of college life.</small>
	</li>
	<li> <strong>Beijing Outstanding Graduates</strong>, 2017.06</li>
	<li> <strong>Outstanding Thesis</strong>, Tsinghua University, 2017.06 <br>
		<small>Thesis submitted for the degree of Bachelor of Engineering. Top-1 score in the Department of CST.</small>
	</li>
	<li> <strong>Zhong Shimo Scholarship</strong>, Tsinghua University, 2016.12 <br>
		<small>The highest award in the Department of CST. Only 5 students (including undergraduate, master and Ph.D. students) are awarded each year.</small>
	</li>
	<li> <strong>Zhong Shimo Scholarship</strong>, Tsinghua University, 2015.12</li>
	<li> <strong>The CCF Outstanding Undergraduate Award</strong>, CCF, 2015.06 <br>
		<small>Only 4 students in Tsinghua are awarded by <a href="http://www.ccf.org.cn">China Computer Federation</a> each year.</small>
	</li>
	<li> <strong>ST Engineering Overseas Scholarship</strong>, Singapore Technologies Engineering, 2015.05</li>
	<li> <strong>China National Scholarship</strong>, Tsinghua University, 2014.10</li>-->

</ul>

<h2>Teaching</h2>
2023.06, <strong>Lecturer</strong> in CCF ADL140: Robust Machine Learning<br>
2019 spring, <strong>Head TA</strong> in Statistical Machine Learning, instructed by Prof. Jun Zhu 

<div id="footer">
	<div id="footer-text"></div>
</div>
Last update: Aug. 2024 by Yinpeng Dong
</body></html>

